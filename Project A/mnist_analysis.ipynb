{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk5Vl1k_ck9Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# Acknowledgement to\n",
        "# https://github.com/kuangliu/pytorch-cifar,\n",
        "# https://github.com/BIGBALLON/CIFAR-ZOO,\n",
        "\n",
        "\n",
        "''' Swish activation '''\n",
        "class Swish(nn.Module): # Swish(x) = x∗σ(x)\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input * torch.sigmoid(input)\n",
        "\n",
        "\n",
        "''' MLP '''\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, channel, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc_1 = nn.Linear(28*28*1 if channel==1 else 32*32*3, 128)\n",
        "        self.fc_2 = nn.Linear(128, 128)\n",
        "        self.fc_3 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.view(x.size(0), -1)\n",
        "        out = F.relu(self.fc_1(out))\n",
        "        out = F.relu(self.fc_2(out))\n",
        "        out = self.fc_3(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "''' ConvNet '''\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, channel, num_classes, net_width, net_depth, net_act, net_norm, net_pooling, im_size = (32,32)):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        self.features, shape_feat = self._make_layers(channel, net_width, net_depth, net_norm, net_act, net_pooling, im_size)\n",
        "        num_feat = shape_feat[0]*shape_feat[1]*shape_feat[2]\n",
        "        self.classifier = nn.Linear(num_feat, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def embed(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        return out\n",
        "\n",
        "    def _get_activation(self, net_act):\n",
        "        if net_act == 'sigmoid':\n",
        "            return nn.Sigmoid()\n",
        "        elif net_act == 'relu':\n",
        "            return nn.ReLU(inplace=True)\n",
        "        elif net_act == 'leakyrelu':\n",
        "            return nn.LeakyReLU(negative_slope=0.01)\n",
        "        elif net_act == 'swish':\n",
        "            return Swish()\n",
        "        else:\n",
        "            exit('unknown activation function: %s'%net_act)\n",
        "\n",
        "    def _get_pooling(self, net_pooling):\n",
        "        if net_pooling == 'maxpooling':\n",
        "            return nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        elif net_pooling == 'avgpooling':\n",
        "            return nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        elif net_pooling == 'none':\n",
        "            return None\n",
        "        else:\n",
        "            exit('unknown net_pooling: %s'%net_pooling)\n",
        "\n",
        "    def _get_normlayer(self, net_norm, shape_feat):\n",
        "        # shape_feat = (c*h*w)\n",
        "        if net_norm == 'batchnorm':\n",
        "            return nn.BatchNorm2d(shape_feat[0], affine=True)\n",
        "        elif net_norm == 'layernorm':\n",
        "            return nn.LayerNorm(shape_feat, elementwise_affine=True)\n",
        "        elif net_norm == 'instancenorm':\n",
        "            return nn.GroupNorm(shape_feat[0], shape_feat[0], affine=True)\n",
        "        elif net_norm == 'groupnorm':\n",
        "            return nn.GroupNorm(4, shape_feat[0], affine=True)\n",
        "        elif net_norm == 'none':\n",
        "            return None\n",
        "        else:\n",
        "            exit('unknown net_norm: %s'%net_norm)\n",
        "\n",
        "    def _make_layers(self, channel, net_width, net_depth, net_norm, net_act, net_pooling, im_size):\n",
        "        layers = []\n",
        "        in_channels = channel\n",
        "        if im_size[0] == 28:\n",
        "            im_size = (32, 32)\n",
        "        shape_feat = [in_channels, im_size[0], im_size[1]]\n",
        "        for d in range(net_depth):\n",
        "            layers += [nn.Conv2d(in_channels, net_width, kernel_size=3, padding=3 if channel == 1 and d == 0 else 1)]\n",
        "            shape_feat[0] = net_width\n",
        "            if net_norm != 'none':\n",
        "                layers += [self._get_normlayer(net_norm, shape_feat)]\n",
        "            layers += [self._get_activation(net_act)]\n",
        "            in_channels = net_width\n",
        "            if net_pooling != 'none':\n",
        "                layers += [self._get_pooling(net_pooling)]\n",
        "                shape_feat[1] //= 2\n",
        "                shape_feat[2] //= 2\n",
        "\n",
        "        return nn.Sequential(*layers), shape_feat\n",
        "\n",
        "\n",
        "\n",
        "''' LeNet '''\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, channel, num_classes):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(channel, 6, kernel_size=5, padding=2 if channel==1 else 0),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.fc_1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc_2 = nn.Linear(120, 84)\n",
        "        self.fc_3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc_1(x))\n",
        "        x = F.relu(self.fc_2(x))\n",
        "        x = self.fc_3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "''' AlexNet '''\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, channel, num_classes):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(channel, 128, kernel_size=5, stride=1, padding=4 if channel==1 else 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(192, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(192, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.fc = nn.Linear(192 * 4 * 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def embed(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "\n",
        "''' AlexNetBN '''\n",
        "class AlexNetBN(nn.Module):\n",
        "    def __init__(self, channel, num_classes):\n",
        "        super(AlexNetBN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(channel, 128, kernel_size=5, stride=1, padding=4 if channel==1 else 2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 192, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(192, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 192, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(192, 192, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.fc = nn.Linear(192 * 4 * 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def embed(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "\n",
        "''' VGG '''\n",
        "cfg_vgg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name, channel, num_classes, norm='instancenorm'):\n",
        "        super(VGG, self).__init__()\n",
        "        self.channel = channel\n",
        "        self.features = self._make_layers(cfg_vgg[vgg_name], norm)\n",
        "        self.classifier = nn.Linear(512 if vgg_name != 'VGGS' else 128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def embed(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "    def _make_layers(self, cfg, norm):\n",
        "        layers = []\n",
        "        in_channels = self.channel\n",
        "        for ic, x in enumerate(cfg):\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=3 if self.channel==1 and ic==0 else 1),\n",
        "                           nn.GroupNorm(x, x, affine=True) if norm=='instancenorm' else nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def VGG11(channel, num_classes):\n",
        "    return VGG('VGG11', channel, num_classes)\n",
        "def VGG11BN(channel, num_classes):\n",
        "    return VGG('VGG11', channel, num_classes, norm='batchnorm')\n",
        "def VGG13(channel, num_classes):\n",
        "    return VGG('VGG13', channel, num_classes)\n",
        "def VGG16(channel, num_classes):\n",
        "    return VGG('VGG16', channel, num_classes)\n",
        "def VGG19(channel, num_classes):\n",
        "    return VGG('VGG19', channel, num_classes)\n",
        "\n",
        "\n",
        "''' ResNet_AP '''\n",
        "# The conv(stride=2) is replaced by conv(stride=1) + avgpool(kernel_size=2, stride=2)\n",
        "\n",
        "class BasicBlock_AP(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, norm='instancenorm'):\n",
        "        super(BasicBlock_AP, self).__init__()\n",
        "        self.norm = norm\n",
        "        self.stride = stride\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=1, padding=1, bias=False) # modification\n",
        "        self.bn1 = nn.GroupNorm(planes, planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.GroupNorm(planes, planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=1, bias=False),\n",
        "                nn.AvgPool2d(kernel_size=2, stride=2), # modification\n",
        "                nn.GroupNorm(self.expansion * planes, self.expansion * planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        if self.stride != 1: # modification\n",
        "            out = F.avg_pool2d(out, kernel_size=2, stride=2)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck_AP(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, norm='instancenorm'):\n",
        "        super(Bottleneck_AP, self).__init__()\n",
        "        self.norm = norm\n",
        "        self.stride = stride\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.GroupNorm(planes, planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False) # modification\n",
        "        self.bn2 = nn.GroupNorm(planes, planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.GroupNorm(self.expansion * planes, self.expansion * planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=1, bias=False),\n",
        "                nn.AvgPool2d(kernel_size=2, stride=2),  # modification\n",
        "                nn.GroupNorm(self.expansion * planes, self.expansion * planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        if self.stride != 1: # modification\n",
        "            out = F.avg_pool2d(out, kernel_size=2, stride=2)\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet_AP(nn.Module):\n",
        "    def __init__(self, block, num_blocks, channel=3, num_classes=10, norm='instancenorm'):\n",
        "        super(ResNet_AP, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.norm = norm\n",
        "\n",
        "        self.conv1 = nn.Conv2d(channel, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.GroupNorm(64, 64, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.classifier = nn.Linear(512 * block.expansion * 3 * 3 if channel==1 else 512 * block.expansion * 4 * 4, num_classes)  # modification\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, self.norm))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, kernel_size=1, stride=1) # modification\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def embed(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, kernel_size=1, stride=1) # modification\n",
        "        out = out.view(out.size(0), -1)\n",
        "        return out\n",
        "\n",
        "def ResNet18BN_AP(channel, num_classes):\n",
        "    return ResNet_AP(BasicBlock_AP, [2,2,2,2], channel=channel, num_classes=num_classes, norm='batchnorm')\n",
        "\n",
        "def ResNet18_AP(channel, num_classes):\n",
        "    return ResNet_AP(BasicBlock_AP, [2,2,2,2], channel=channel, num_classes=num_classes)\n",
        "\n",
        "\n",
        "''' ResNet '''\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, norm='instancenorm'):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.norm = norm\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.GroupNorm(planes, planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.GroupNorm(planes, planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.GroupNorm(self.expansion*planes, self.expansion*planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, norm='instancenorm'):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.norm = norm\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.GroupNorm(planes, planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.GroupNorm(planes, planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.GroupNorm(self.expansion*planes, self.expansion*planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.GroupNorm(self.expansion*planes, self.expansion*planes, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, channel=3, num_classes=10, norm='instancenorm'):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.norm = norm\n",
        "\n",
        "        self.conv1 = nn.Conv2d(channel, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.GroupNorm(64, 64, affine=True) if self.norm == 'instancenorm' else nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.classifier = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, self.norm))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def embed(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18BN(channel, num_classes):\n",
        "    return ResNet(BasicBlock, [2,2,2,2], channel=channel, num_classes=num_classes, norm='batchnorm')\n",
        "\n",
        "def ResNet18(channel, num_classes):\n",
        "    return ResNet(BasicBlock, [2,2,2,2], channel=channel, num_classes=num_classes)\n",
        "\n",
        "def ResNet34(channel, num_classes):\n",
        "    return ResNet(BasicBlock, [3,4,6,3], channel=channel, num_classes=num_classes)\n",
        "\n",
        "def ResNet50(channel, num_classes):\n",
        "    return ResNet(Bottleneck, [3,4,6,3], channel=channel, num_classes=num_classes)\n",
        "\n",
        "def ResNet101(channel, num_classes):\n",
        "    return ResNet(Bottleneck, [3,4,23,3], channel=channel, num_classes=num_classes)\n",
        "\n",
        "def ResNet152(channel, num_classes):\n",
        "    return ResNet(Bottleneck, [3,8,36,3], channel=channel, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OePBl3IdKCG",
        "outputId": "a1408c8d-91e7-46e8-e0f9-71deaad1a5fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-59d11037293d>:9: DeprecationWarning: Please import `rotate` from the `scipy.ndimage` namespace; the `scipy.ndimage.interpolation` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
            "  from scipy.ndimage.interpolation import rotate as scipyrotate\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from scipy.ndimage.interpolation import rotate as scipyrotate\n",
        "#from networks import MLP, ConvNet, LeNet, AlexNet, AlexNetBN, VGG11, VGG11BN, ResNet18, ResNet18BN_AP, ResNet18BN\n",
        "\n",
        "def get_dataset(dataset, data_path):\n",
        "    if dataset == 'MNIST':\n",
        "        channel = 1\n",
        "        im_size = (28, 28)\n",
        "        num_classes = 10\n",
        "        mean = [0.1307]\n",
        "        std = [0.3081]\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
        "        dst_train = datasets.MNIST(data_path, train=True, download=True, transform=transform) # no augmentation\n",
        "        dst_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
        "        class_names = [str(c) for c in range(num_classes)]\n",
        "\n",
        "    elif dataset == 'FashionMNIST':\n",
        "        channel = 1\n",
        "        im_size = (28, 28)\n",
        "        num_classes = 10\n",
        "        mean = [0.2861]\n",
        "        std = [0.3530]\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
        "        dst_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transform) # no augmentation\n",
        "        dst_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transform)\n",
        "        class_names = dst_train.classes\n",
        "\n",
        "    elif dataset == 'SVHN':\n",
        "        channel = 3\n",
        "        im_size = (32, 32)\n",
        "        num_classes = 10\n",
        "        mean = [0.4377, 0.4438, 0.4728]\n",
        "        std = [0.1980, 0.2010, 0.1970]\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
        "        dst_train = datasets.SVHN(data_path, split='train', download=True, transform=transform)  # no augmentation\n",
        "        dst_test = datasets.SVHN(data_path, split='test', download=True, transform=transform)\n",
        "        class_names = [str(c) for c in range(num_classes)]\n",
        "\n",
        "    elif dataset == 'CIFAR10':\n",
        "        channel = 3\n",
        "        im_size = (32, 32)\n",
        "        num_classes = 10\n",
        "        mean = [0.4914, 0.4822, 0.4465]\n",
        "        std = [0.2023, 0.1994, 0.2010]\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
        "        dst_train = datasets.CIFAR10(data_path, train=True, download=True, transform=transform) # no augmentation\n",
        "        dst_test = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n",
        "        class_names = dst_train.classes\n",
        "\n",
        "    elif dataset == 'CIFAR100':\n",
        "        channel = 3\n",
        "        im_size = (32, 32)\n",
        "        num_classes = 100\n",
        "        mean = [0.5071, 0.4866, 0.4409]\n",
        "        std = [0.2673, 0.2564, 0.2762]\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=mean, std=std)])\n",
        "        dst_train = datasets.CIFAR100(data_path, train=True, download=True, transform=transform) # no augmentation\n",
        "        dst_test = datasets.CIFAR100(data_path, train=False, download=True, transform=transform)\n",
        "        class_names = dst_train.classes\n",
        "\n",
        "    elif dataset == 'TinyImageNet':\n",
        "        channel = 3\n",
        "        im_size = (64, 64)\n",
        "        num_classes = 200\n",
        "        mean = [0.485, 0.456, 0.406]\n",
        "        std = [0.229, 0.224, 0.225]\n",
        "        data = torch.load(os.path.join(data_path, 'tinyimagenet.pt'), map_location='cpu')\n",
        "\n",
        "        class_names = data['classes']\n",
        "\n",
        "        images_train = data['images_train']\n",
        "        labels_train = data['labels_train']\n",
        "        images_train = images_train.detach().float() / 255.0\n",
        "        labels_train = labels_train.detach()\n",
        "        for c in range(channel):\n",
        "            images_train[:,c] = (images_train[:,c] - mean[c])/std[c]\n",
        "        dst_train = TensorDataset(images_train, labels_train)  # no augmentation\n",
        "\n",
        "        images_val = data['images_val']\n",
        "        labels_val = data['labels_val']\n",
        "        images_val = images_val.detach().float() / 255.0\n",
        "        labels_val = labels_val.detach()\n",
        "\n",
        "        for c in range(channel):\n",
        "            images_val[:, c] = (images_val[:, c] - mean[c]) / std[c]\n",
        "\n",
        "        dst_test = TensorDataset(images_val, labels_val)  # no augmentation\n",
        "\n",
        "    else:\n",
        "        exit('unknown dataset: %s'%dataset)\n",
        "\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(dst_test, batch_size=256, shuffle=False, num_workers=0)\n",
        "    return channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader\n",
        "\n",
        "\n",
        "\n",
        "class TensorDataset(Dataset):\n",
        "    def __init__(self, images, labels): # images: n x c x h x w tensor\n",
        "        self.images = images.detach().float()\n",
        "        self.labels = labels.detach()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.images[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "def get_default_convnet_setting():\n",
        "    net_width, net_depth, net_act, net_norm, net_pooling = 128, 3, 'relu', 'instancenorm', 'avgpooling'\n",
        "    return net_width, net_depth, net_act, net_norm, net_pooling\n",
        "\n",
        "\n",
        "\n",
        "def get_network(model, channel, num_classes, im_size=(32, 32)):\n",
        "    torch.random.manual_seed(int(time.time() * 1000) % 100000)\n",
        "    net_width, net_depth, net_act, net_norm, net_pooling = get_default_convnet_setting()\n",
        "\n",
        "    if model == 'MLP':\n",
        "        net = MLP(channel=channel, num_classes=num_classes)\n",
        "    elif model == 'ConvNet':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'LeNet':\n",
        "        net = LeNet(channel=channel, num_classes=num_classes)\n",
        "    elif model == 'AlexNet':\n",
        "        net = AlexNet(channel=channel, num_classes=num_classes)\n",
        "    elif model == 'AlexNetBN':\n",
        "        net = AlexNetBN(channel=channel, num_classes=num_classes)\n",
        "    elif model == 'VGG11':\n",
        "        net = VGG11( channel=channel, num_classes=num_classes)\n",
        "    elif model == 'VGG11BN':\n",
        "        net = VGG11BN(channel=channel, num_classes=num_classes)\n",
        "    elif model == 'ResNet18':\n",
        "        net = ResNet18(channel=channel, num_classes=num_classes)\n",
        "    elif model == 'ResNet18BN_AP':\n",
        "        net = ResNet18BN_AP(channel=channel, num_classes=num_classes)\n",
        "    elif model == 'ResNet18BN':\n",
        "        net = ResNet18BN(channel=channel, num_classes=num_classes)\n",
        "\n",
        "    elif model == 'ConvNetD1':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=1, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetD2':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=2, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetD3':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=3, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetD4':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=4, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "\n",
        "    elif model == 'ConvNetW32':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=32, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetW64':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=64, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetW128':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=128, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetW256':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=256, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "\n",
        "    elif model == 'ConvNetAS':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act='sigmoid', net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetAR':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act='relu', net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetAL':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act='leakyrelu', net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetASwish':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act='swish', net_norm=net_norm, net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetASwishBN':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act='swish', net_norm='batchnorm', net_pooling=net_pooling, im_size=im_size)\n",
        "\n",
        "    elif model == 'ConvNetNN':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm='none', net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetBN':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm='batchnorm', net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetLN':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm='layernorm', net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetIN':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm='instancenorm', net_pooling=net_pooling, im_size=im_size)\n",
        "    elif model == 'ConvNetGN':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm='groupnorm', net_pooling=net_pooling, im_size=im_size)\n",
        "\n",
        "    elif model == 'ConvNetNP':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling='none', im_size=im_size)\n",
        "    elif model == 'ConvNetMP':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling='maxpooling', im_size=im_size)\n",
        "    elif model == 'ConvNetAP':\n",
        "        net = ConvNet(channel=channel, num_classes=num_classes, net_width=net_width, net_depth=net_depth, net_act=net_act, net_norm=net_norm, net_pooling='avgpooling', im_size=im_size)\n",
        "\n",
        "    else:\n",
        "        net = None\n",
        "        exit('unknown model: %s'%model)\n",
        "\n",
        "    gpu_num = torch.cuda.device_count()\n",
        "    if gpu_num>0:\n",
        "        device = 'cuda'\n",
        "        if gpu_num>1:\n",
        "            net = nn.DataParallel(net)\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "    net = net.to(device)\n",
        "\n",
        "    return net\n",
        "\n",
        "\n",
        "\n",
        "def get_time():\n",
        "    return str(time.strftime(\"[%Y-%m-%d %H:%M:%S]\", time.localtime()))\n",
        "\n",
        "\n",
        "\n",
        "def distance_wb(gwr, gws):\n",
        "    shape = gwr.shape\n",
        "    if len(shape) == 4: # conv, out*in*h*w\n",
        "        gwr = gwr.reshape(shape[0], shape[1] * shape[2] * shape[3])\n",
        "        gws = gws.reshape(shape[0], shape[1] * shape[2] * shape[3])\n",
        "    elif len(shape) == 3:  # layernorm, C*h*w\n",
        "        gwr = gwr.reshape(shape[0], shape[1] * shape[2])\n",
        "        gws = gws.reshape(shape[0], shape[1] * shape[2])\n",
        "    elif len(shape) == 2: # linear, out*in\n",
        "        tmp = 'do nothing'\n",
        "    elif len(shape) == 1: # batchnorm/instancenorm, C; groupnorm x, bias\n",
        "        gwr = gwr.reshape(1, shape[0])\n",
        "        gws = gws.reshape(1, shape[0])\n",
        "        return torch.tensor(0, dtype=torch.float, device=gwr.device)\n",
        "\n",
        "    dis_weight = torch.sum(1 - torch.sum(gwr * gws, dim=-1) / (torch.norm(gwr, dim=-1) * torch.norm(gws, dim=-1) + 0.000001))\n",
        "    dis = dis_weight\n",
        "    return dis\n",
        "\n",
        "\n",
        "\n",
        "def match_loss(gw_syn, gw_real, args):\n",
        "    dis = torch.tensor(0.0).to(args.device)\n",
        "\n",
        "    if args.dis_metric == 'ours':\n",
        "        for ig in range(len(gw_real)):\n",
        "            gwr = gw_real[ig]\n",
        "            gws = gw_syn[ig]\n",
        "            dis += distance_wb(gwr, gws)\n",
        "\n",
        "    elif args.dis_metric == 'mse':\n",
        "        gw_real_vec = []\n",
        "        gw_syn_vec = []\n",
        "        for ig in range(len(gw_real)):\n",
        "            gw_real_vec.append(gw_real[ig].reshape((-1)))\n",
        "            gw_syn_vec.append(gw_syn[ig].reshape((-1)))\n",
        "        gw_real_vec = torch.cat(gw_real_vec, dim=0)\n",
        "        gw_syn_vec = torch.cat(gw_syn_vec, dim=0)\n",
        "        dis = torch.sum((gw_syn_vec - gw_real_vec)**2)\n",
        "\n",
        "    elif args.dis_metric == 'cos':\n",
        "        gw_real_vec = []\n",
        "        gw_syn_vec = []\n",
        "        for ig in range(len(gw_real)):\n",
        "            gw_real_vec.append(gw_real[ig].reshape((-1)))\n",
        "            gw_syn_vec.append(gw_syn[ig].reshape((-1)))\n",
        "        gw_real_vec = torch.cat(gw_real_vec, dim=0)\n",
        "        gw_syn_vec = torch.cat(gw_syn_vec, dim=0)\n",
        "        dis = 1 - torch.sum(gw_real_vec * gw_syn_vec, dim=-1) / (torch.norm(gw_real_vec, dim=-1) * torch.norm(gw_syn_vec, dim=-1) + 0.000001)\n",
        "\n",
        "    else:\n",
        "        exit('unknown distance function: %s'%args.dis_metric)\n",
        "\n",
        "    return dis\n",
        "\n",
        "\n",
        "\n",
        "def get_loops(ipc):\n",
        "    # Get the two hyper-parameters of outer-loop and inner-loop.\n",
        "    # The following values are empirically good.\n",
        "    if ipc == 1:\n",
        "        outer_loop, inner_loop = 1, 1\n",
        "    elif ipc == 10:\n",
        "        outer_loop, inner_loop = 10, 50\n",
        "    elif ipc == 20:\n",
        "        outer_loop, inner_loop = 20, 25\n",
        "    elif ipc == 30:\n",
        "        outer_loop, inner_loop = 30, 20\n",
        "    elif ipc == 40:\n",
        "        outer_loop, inner_loop = 40, 15\n",
        "    elif ipc == 50:\n",
        "        outer_loop, inner_loop = 50, 10\n",
        "    else:\n",
        "        outer_loop, inner_loop = 0, 0\n",
        "        exit('loop hyper-parameters are not defined for %d ipc'%ipc)\n",
        "    return outer_loop, inner_loop\n",
        "\n",
        "\n",
        "\n",
        "def epoch(mode, dataloader, net, optimizer, criterion, args, aug):\n",
        "    loss_avg, acc_avg, num_exp = 0, 0, 0\n",
        "    net = net.to(args.device)\n",
        "    criterion = criterion.to(args.device)\n",
        "\n",
        "    if mode == 'train':\n",
        "        net.train()\n",
        "    else:\n",
        "        net.eval()\n",
        "\n",
        "    for i_batch, datum in enumerate(dataloader):\n",
        "\n",
        "        img = datum[0].float().to(args.device)\n",
        "        #print(datum, img)\n",
        "        #datum[0] = torch.tensor(datum[0])\n",
        "        if aug:\n",
        "            if args.dsa:\n",
        "                img = DiffAugment(img, args.dsa_strategy, param=args.dsa_param)\n",
        "            else:\n",
        "                img = augment(img, args.dc_aug_param, device=args.device)\n",
        "        lab = torch.tensor(datum[1]).long().to(args.device)\n",
        "        lab = lab.unsqueeze(0)\n",
        "        if img.ndim == 3:  # If shape is [128, 32, 32]\n",
        "            img = img.unsqueeze(0)\n",
        "\n",
        "\n",
        "        n_b = lab.shape[0]\n",
        "\n",
        "        output = net(img)\n",
        "        loss = criterion(output, lab)\n",
        "        acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
        "\n",
        "        loss_avg += loss.item()*n_b\n",
        "        acc_avg += acc\n",
        "        num_exp += n_b\n",
        "\n",
        "        if mode == 'train':\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    loss_avg /= num_exp\n",
        "    acc_avg /= num_exp\n",
        "\n",
        "    return loss_avg, acc_avg\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_synset(it_eval, net, images_train, labels_train, testloader, args):\n",
        "    net = net.to(args.device)\n",
        "    images_train = images_train.to(args.device)\n",
        "    labels_train = labels_train.to(args.device)\n",
        "    lr = float(args.lr_net)\n",
        "    Epoch = int(args.epoch_eval_train)\n",
        "    lr_schedule = [Epoch//2+1]\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=0.0005)\n",
        "    criterion = nn.CrossEntropyLoss().to(args.device)\n",
        "\n",
        "    dst_train = TensorDataset(images_train, labels_train)\n",
        "    trainloader = torch.utils.data.DataLoader(dst_train, batch_size=args.batch_train, shuffle=True, num_workers=0)\n",
        "\n",
        "    start = time.time()\n",
        "    for ep in range(Epoch+1):\n",
        "        loss_train, acc_train = epoch('train', trainloader, net, optimizer, criterion, args, aug = True)\n",
        "        if ep in lr_schedule:\n",
        "            lr *= 0.1\n",
        "            optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "    time_train = time.time() - start\n",
        "    loss_test, acc_test = epoch('test', testloader, net, optimizer, criterion, args, aug = False)\n",
        "    print('%s Evaluate_%02d: epoch = %04d train time = %d s train loss = %.6f train acc = %.4f, test acc = %.4f' % (get_time(), it_eval, Epoch, int(time_train), loss_train, acc_train, acc_test))\n",
        "\n",
        "    return net, acc_train, acc_test\n",
        "\n",
        "\n",
        "\n",
        "def augment(images, dc_aug_param, device):\n",
        "    # This can be sped up in the future.\n",
        "\n",
        "    if dc_aug_param != None and dc_aug_param['strategy'] != 'none':\n",
        "        scale = dc_aug_param['scale']\n",
        "        crop = dc_aug_param['crop']\n",
        "        rotate = dc_aug_param['rotate']\n",
        "        noise = dc_aug_param['noise']\n",
        "        strategy = dc_aug_param['strategy']\n",
        "\n",
        "        shape = images.shape\n",
        "        mean = []\n",
        "        for c in range(shape[1]):\n",
        "            mean.append(float(torch.mean(images[:,c])))\n",
        "\n",
        "        def cropfun(i):\n",
        "            im_ = torch.zeros(shape[1],shape[2]+crop*2,shape[3]+crop*2, dtype=torch.float, device=device)\n",
        "            for c in range(shape[1]):\n",
        "                im_[c] = mean[c]\n",
        "            im_[:, crop:crop+shape[2], crop:crop+shape[3]] = images[i]\n",
        "            r, c = np.random.permutation(crop*2)[0], np.random.permutation(crop*2)[0]\n",
        "            images[i] = im_[:, r:r+shape[2], c:c+shape[3]]\n",
        "\n",
        "        def scalefun(i):\n",
        "            h = int((np.random.uniform(1 - scale, 1 + scale)) * shape[2])\n",
        "            w = int((np.random.uniform(1 - scale, 1 + scale)) * shape[2])\n",
        "            tmp = F.interpolate(images[i:i + 1], [h, w], )[0]\n",
        "            mhw = max(h, w, shape[2], shape[3])\n",
        "            im_ = torch.zeros(shape[1], mhw, mhw, dtype=torch.float, device=device)\n",
        "            r = int((mhw - h) / 2)\n",
        "            c = int((mhw - w) / 2)\n",
        "            im_[:, r:r + h, c:c + w] = tmp\n",
        "            r = int((mhw - shape[2]) / 2)\n",
        "            c = int((mhw - shape[3]) / 2)\n",
        "            images[i] = im_[:, r:r + shape[2], c:c + shape[3]]\n",
        "\n",
        "        def rotatefun(i):\n",
        "            im_ = scipyrotate(images[i].cpu().data.numpy(), angle=np.random.randint(-rotate, rotate), axes=(-2, -1), cval=np.mean(mean))\n",
        "            r = int((im_.shape[-2] - shape[-2]) / 2)\n",
        "            c = int((im_.shape[-1] - shape[-1]) / 2)\n",
        "            images[i] = torch.tensor(im_[:, r:r + shape[-2], c:c + shape[-1]], dtype=torch.float, device=device)\n",
        "\n",
        "        def noisefun(i):\n",
        "            images[i] = images[i] + noise * torch.randn(shape[1:], dtype=torch.float, device=device)\n",
        "\n",
        "\n",
        "        augs = strategy.split('_')\n",
        "\n",
        "        for i in range(shape[0]):\n",
        "            choice = np.random.permutation(augs)[0] # randomly implement one augmentation\n",
        "            if choice == 'crop':\n",
        "                cropfun(i)\n",
        "            elif choice == 'scale':\n",
        "                scalefun(i)\n",
        "            elif choice == 'rotate':\n",
        "                rotatefun(i)\n",
        "            elif choice == 'noise':\n",
        "                noisefun(i)\n",
        "\n",
        "    return images\n",
        "\n",
        "\n",
        "\n",
        "def get_daparam(dataset, model, model_eval, ipc):\n",
        "    # We find that augmentation doesn't always benefit the performance.\n",
        "    # So we do augmentation for some of the settings.\n",
        "\n",
        "    dc_aug_param = dict()\n",
        "    dc_aug_param['crop'] = 4\n",
        "    dc_aug_param['scale'] = 0.2\n",
        "    dc_aug_param['rotate'] = 45\n",
        "    dc_aug_param['noise'] = 0.001\n",
        "    dc_aug_param['strategy'] = 'none'\n",
        "\n",
        "    if dataset == 'MNIST':\n",
        "        dc_aug_param['strategy'] = 'crop_scale_rotate'\n",
        "\n",
        "    if model_eval in ['ConvNetBN']: # Data augmentation makes model training with Batch Norm layer easier.\n",
        "        dc_aug_param['strategy'] = 'crop_noise'\n",
        "\n",
        "    return dc_aug_param\n",
        "\n",
        "\n",
        "def get_eval_pool(eval_mode, model, model_eval):\n",
        "    if eval_mode == 'M': # multiple architectures\n",
        "        model_eval_pool = ['MLP', 'ConvNet', 'LeNet', 'AlexNet', 'VGG11', 'ResNet18']\n",
        "    elif eval_mode == 'B':  # multiple architectures with BatchNorm for DM experiments\n",
        "        model_eval_pool = ['ConvNetBN', 'ConvNetASwishBN', 'AlexNetBN', 'VGG11BN', 'ResNet18BN']\n",
        "    elif eval_mode == 'W': # ablation study on network width\n",
        "        model_eval_pool = ['ConvNetW32', 'ConvNetW64', 'ConvNetW128', 'ConvNetW256']\n",
        "    elif eval_mode == 'D': # ablation study on network depth\n",
        "        model_eval_pool = ['ConvNetD1', 'ConvNetD2', 'ConvNetD3', 'ConvNetD4']\n",
        "    elif eval_mode == 'A': # ablation study on network activation function\n",
        "        model_eval_pool = ['ConvNetAS', 'ConvNetAR', 'ConvNetAL', 'ConvNetASwish']\n",
        "    elif eval_mode == 'P': # ablation study on network pooling layer\n",
        "        model_eval_pool = ['ConvNetNP', 'ConvNetMP', 'ConvNetAP']\n",
        "    elif eval_mode == 'N': # ablation study on network normalization layer\n",
        "        model_eval_pool = ['ConvNetNN', 'ConvNetBN', 'ConvNetLN', 'ConvNetIN', 'ConvNetGN']\n",
        "    elif eval_mode == 'S': # itself\n",
        "        if 'BN' in model:\n",
        "            print('Attention: Here I will replace BN with IN in evaluation, as the synthetic set is too small to measure BN hyper-parameters.')\n",
        "        model_eval_pool = [model[:model.index('BN')]] if 'BN' in model else [model]\n",
        "    elif eval_mode == 'SS':  # itself\n",
        "        model_eval_pool = [model]\n",
        "    else:\n",
        "        model_eval_pool = [model_eval]\n",
        "    return model_eval_pool\n",
        "\n",
        "\n",
        "class ParamDiffAug():\n",
        "    def __init__(self):\n",
        "        self.aug_mode = 'S' #'multiple or single'\n",
        "        self.prob_flip = 0.5\n",
        "        self.ratio_scale = 1.2\n",
        "        self.ratio_rotate = 15.0\n",
        "        self.ratio_crop_pad = 0.125\n",
        "        self.ratio_cutout = 0.5 # the size would be 0.5x0.5\n",
        "        self.brightness = 1.0\n",
        "        self.saturation = 2.0\n",
        "        self.contrast = 0.5\n",
        "\n",
        "\n",
        "def set_seed_DiffAug(param):\n",
        "    if param.latestseed == -1:\n",
        "        return\n",
        "    else:\n",
        "        torch.random.manual_seed(param.latestseed)\n",
        "        param.latestseed += 1\n",
        "\n",
        "\n",
        "def DiffAugment(x, strategy='', seed = -1, param = None):\n",
        "    if strategy == 'None' or strategy == 'none' or strategy == '':\n",
        "        return x\n",
        "\n",
        "    if seed == -1:\n",
        "        param.Siamese = False\n",
        "    else:\n",
        "        param.Siamese = True\n",
        "\n",
        "    param.latestseed = seed\n",
        "\n",
        "    if strategy:\n",
        "        if param.aug_mode == 'M': # original\n",
        "            for p in strategy.split('_'):\n",
        "                for f in AUGMENT_FNS[p]:\n",
        "                    x = f(x, param)\n",
        "        elif param.aug_mode == 'S':\n",
        "            pbties = strategy.split('_')\n",
        "            set_seed_DiffAug(param)\n",
        "            p = pbties[torch.randint(0, len(pbties), size=(1,)).item()]\n",
        "            for f in AUGMENT_FNS[p]:\n",
        "                x = f(x, param)\n",
        "        else:\n",
        "            exit('unknown augmentation mode: %s'%param.aug_mode)\n",
        "        x = x.contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "# We implement the following differentiable augmentation strategies based on the code provided in https://github.com/mit-han-lab/data-efficient-gans.\n",
        "def rand_scale(x, param):\n",
        "    # x>1, max scale\n",
        "    # sx, sy: (0, +oo), 1: orignial size, 0.5: enlarge 2 times\n",
        "    ratio = param.ratio_scale\n",
        "    set_seed_DiffAug(param)\n",
        "    sx = torch.rand(x.shape[0]) * (ratio - 1.0/ratio) + 1.0/ratio\n",
        "    set_seed_DiffAug(param)\n",
        "    sy = torch.rand(x.shape[0]) * (ratio - 1.0/ratio) + 1.0/ratio\n",
        "    theta = [[[sx[i], 0,  0],\n",
        "            [0,  sy[i], 0],] for i in range(x.shape[0])]\n",
        "    theta = torch.tensor(theta, dtype=torch.float)\n",
        "    if param.Siamese: # Siamese augmentation:\n",
        "        theta[:] = theta[0]\n",
        "    grid = F.affine_grid(theta, x.shape).to(x.device)\n",
        "    x = F.grid_sample(x, grid)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_rotate(x, param): # [-180, 180], 90: anticlockwise 90 degree\n",
        "    ratio = param.ratio_rotate\n",
        "    set_seed_DiffAug(param)\n",
        "    theta = (torch.rand(x.shape[0]) - 0.5) * 2 * ratio / 180 * float(np.pi)\n",
        "    theta = [[[torch.cos(theta[i]), torch.sin(-theta[i]), 0],\n",
        "        [torch.sin(theta[i]), torch.cos(theta[i]),  0],]  for i in range(x.shape[0])]\n",
        "    theta = torch.tensor(theta, dtype=torch.float)\n",
        "    if param.Siamese: # Siamese augmentation:\n",
        "        theta[:] = theta[0]\n",
        "    grid = F.affine_grid(theta, x.shape).to(x.device)\n",
        "    x = F.grid_sample(x, grid)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_flip(x, param):\n",
        "    prob = param.prob_flip\n",
        "    set_seed_DiffAug(param)\n",
        "    randf = torch.rand(x.size(0), 1, 1, 1, device=x.device)\n",
        "    if param.Siamese: # Siamese augmentation:\n",
        "        randf[:] = randf[0]\n",
        "    return torch.where(randf < prob, x.flip(3), x)\n",
        "\n",
        "\n",
        "def rand_brightness(x, param):\n",
        "    ratio = param.brightness\n",
        "    set_seed_DiffAug(param)\n",
        "    randb = torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)\n",
        "    if param.Siamese:  # Siamese augmentation:\n",
        "        randb[:] = randb[0]\n",
        "    x = x + (randb - 0.5)*ratio\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_saturation(x, param):\n",
        "    ratio = param.saturation\n",
        "    x_mean = x.mean(dim=1, keepdim=True)\n",
        "    set_seed_DiffAug(param)\n",
        "    rands = torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)\n",
        "    if param.Siamese:  # Siamese augmentation:\n",
        "        rands[:] = rands[0]\n",
        "    x = (x - x_mean) * (rands * ratio) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_contrast(x, param):\n",
        "    ratio = param.contrast\n",
        "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
        "    set_seed_DiffAug(param)\n",
        "    randc = torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device)\n",
        "    if param.Siamese:  # Siamese augmentation:\n",
        "        randc[:] = randc[0]\n",
        "    x = (x - x_mean) * (randc + ratio) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_crop(x, param):\n",
        "    # The image is padded on its surrounding and then cropped.\n",
        "    ratio = param.ratio_crop_pad\n",
        "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    set_seed_DiffAug(param)\n",
        "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    set_seed_DiffAug(param)\n",
        "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    if param.Siamese:  # Siamese augmentation:\n",
        "        translation_x[:] = translation_x[0]\n",
        "        translation_y[:] = translation_y[0]\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
        "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
        "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
        "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_cutout(x, param):\n",
        "    ratio = param.ratio_cutout\n",
        "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    set_seed_DiffAug(param)\n",
        "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    set_seed_DiffAug(param)\n",
        "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    if param.Siamese:  # Siamese augmentation:\n",
        "        offset_x[:] = offset_x[0]\n",
        "        offset_y[:] = offset_y[0]\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
        "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
        "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
        "    mask[grid_batch, grid_x, grid_y] = 0\n",
        "    x = x * mask.unsqueeze(1)\n",
        "    return x\n",
        "\n",
        "\n",
        "AUGMENT_FNS = {\n",
        "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
        "    'crop': [rand_crop],\n",
        "    'cutout': [rand_cutout],\n",
        "    'flip': [rand_flip],\n",
        "    'scale': [rand_scale],\n",
        "    'rotate': [rand_rotate],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgZSzzveA_KA",
        "outputId": "a44633b5-c25f-42da-c0c5-f9cf870ebd7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        self.lr_net = 0.01\n",
        "        self.epoch_eval_train = 20\n",
        "        self.batch_train = 256\n",
        "        self.dsa = False\n",
        "        self.dsa_strategy = 'none'\n",
        "        self.dsa_param = None\n",
        "        self.dc_aug_param = None\n",
        "        self.dis_metric = 'cos'\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Docee5JaWc",
        "outputId": "d8817313-437d-4229-9290-8d83d77dd151"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.0MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 487kB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.42MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.20MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch 1/20, Loss: 0.0997, Accuracy: 0.97\n",
            "Epoch 2/20, Loss: 0.0426, Accuracy: 0.99\n",
            "Epoch 3/20, Loss: 0.0308, Accuracy: 0.99\n",
            "Epoch 4/20, Loss: 0.0223, Accuracy: 0.99\n",
            "Epoch 5/20, Loss: 0.0174, Accuracy: 0.99\n",
            "Epoch 6/20, Loss: 0.0138, Accuracy: 1.00\n",
            "Epoch 7/20, Loss: 0.0101, Accuracy: 1.00\n",
            "Epoch 8/20, Loss: 0.0068, Accuracy: 1.00\n",
            "Epoch 9/20, Loss: 0.0052, Accuracy: 1.00\n",
            "Epoch 10/20, Loss: 0.0026, Accuracy: 1.00\n",
            "Epoch 11/20, Loss: 0.0015, Accuracy: 1.00\n",
            "Epoch 12/20, Loss: 0.0007, Accuracy: 1.00\n",
            "Epoch 13/20, Loss: 0.0003, Accuracy: 1.00\n",
            "Epoch 14/20, Loss: 0.0002, Accuracy: 1.00\n",
            "Epoch 15/20, Loss: 0.0001, Accuracy: 1.00\n",
            "Epoch 16/20, Loss: 0.0001, Accuracy: 1.00\n",
            "Epoch 17/20, Loss: 0.0001, Accuracy: 1.00\n",
            "Epoch 18/20, Loss: 0.0001, Accuracy: 1.00\n",
            "Epoch 19/20, Loss: 0.0001, Accuracy: 1.00\n",
            "Epoch 20/20, Loss: 0.0001, Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Task 1 - Question 2 - Part a\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "dataset_name = 'MNIST'\n",
        "data_path = './data'\n",
        "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, test_loader = get_dataset(dataset_name, data_path)\n",
        "\n",
        "model_name = 'ConvNet'\n",
        "model = get_network(model_name, channel, num_classes, im_size)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
        "\n",
        "epochs = 20\n",
        "for epoch_num in range(epochs):\n",
        "    train_loss, train_acc = epoch('train', dst_train, model, optimizer, torch.nn.CrossEntropyLoss(), args, aug=True)\n",
        "    scheduler.step()\n",
        "    print(f\"Epoch {epoch_num + 1}/{epochs}, Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LVoSQrNtAayq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "f240e22f-7603-4cdf-f6f3-7f321affe351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-59d11037293d>:317: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  lab = torch.tensor(datum[1]).long().to(args.device)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected input batch_size (256) to match target batch_size (1).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-63316b58c531>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Accuracy on Original Dataset: {test_acc:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-59d11037293d>\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(mode, dataloader, net, optimizer, criterion, args, aug)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1294\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3479\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3480\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (256) to match target batch_size (1)."
          ]
        }
      ],
      "source": [
        "\n",
        "test_loss, test_acc = epoch('test', test_loader, model, optimizer, torch.nn.CrossEntropyLoss(), args, aug=False)\n",
        "print(f\"Test Accuracy on Original Dataset: {test_acc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Te9qK_jeAbOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18ad290-cd9f-42e6-ec28-91a6ffe30fc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Iteration 1/100, SAM Loss: 0.22240234911441803\n",
            "Iteration 2/100, SAM Loss: 0.5417309403419495\n",
            "Iteration 3/100, SAM Loss: 0.2986135482788086\n",
            "Iteration 4/100, SAM Loss: 0.2558690309524536\n",
            "Iteration 5/100, SAM Loss: 0.6070145964622498\n",
            "Iteration 6/100, SAM Loss: 0.4701980948448181\n",
            "Iteration 7/100, SAM Loss: 0.7169733047485352\n",
            "Iteration 8/100, SAM Loss: 0.2080640345811844\n",
            "Iteration 9/100, SAM Loss: 0.3347090482711792\n",
            "Iteration 10/100, SAM Loss: 0.40220552682876587\n",
            "Iteration 11/100, SAM Loss: 0.4827312231063843\n",
            "Iteration 12/100, SAM Loss: 0.5311076641082764\n",
            "Iteration 13/100, SAM Loss: 0.2974606156349182\n",
            "Iteration 14/100, SAM Loss: 0.4208718538284302\n",
            "Iteration 15/100, SAM Loss: 0.39560651779174805\n",
            "Iteration 16/100, SAM Loss: 0.48074227571487427\n",
            "Iteration 17/100, SAM Loss: 0.4508988857269287\n",
            "Iteration 18/100, SAM Loss: 0.2538187503814697\n",
            "Iteration 19/100, SAM Loss: 0.8521998524665833\n",
            "Iteration 20/100, SAM Loss: 0.2578454613685608\n",
            "Iteration 21/100, SAM Loss: 0.5088582038879395\n",
            "Iteration 22/100, SAM Loss: 0.17791666090488434\n",
            "Iteration 23/100, SAM Loss: 0.4685726761817932\n",
            "Iteration 24/100, SAM Loss: 0.4086371064186096\n",
            "Iteration 25/100, SAM Loss: 0.8044034838676453\n",
            "Iteration 26/100, SAM Loss: 0.2730954885482788\n",
            "Iteration 27/100, SAM Loss: 0.6381112337112427\n",
            "Iteration 28/100, SAM Loss: 0.45685696601867676\n",
            "Iteration 29/100, SAM Loss: 0.4261758327484131\n",
            "Iteration 30/100, SAM Loss: 0.4792785048484802\n",
            "Iteration 31/100, SAM Loss: 0.3811585307121277\n",
            "Iteration 32/100, SAM Loss: 0.2907094955444336\n",
            "Iteration 33/100, SAM Loss: 0.37348222732543945\n",
            "Iteration 34/100, SAM Loss: 0.2617533206939697\n",
            "Iteration 35/100, SAM Loss: 0.381525456905365\n",
            "Iteration 36/100, SAM Loss: 0.1760675460100174\n",
            "Iteration 37/100, SAM Loss: 0.49105513095855713\n",
            "Iteration 38/100, SAM Loss: 0.33795589208602905\n",
            "Iteration 39/100, SAM Loss: 0.18025870621204376\n",
            "Iteration 40/100, SAM Loss: 0.2464926391839981\n",
            "Iteration 41/100, SAM Loss: 0.24741996824741364\n",
            "Iteration 42/100, SAM Loss: 0.2501215934753418\n",
            "Iteration 43/100, SAM Loss: 0.32648539543151855\n",
            "Iteration 44/100, SAM Loss: 0.6097003221511841\n",
            "Iteration 45/100, SAM Loss: 0.44284164905548096\n",
            "Iteration 46/100, SAM Loss: 0.2992212772369385\n",
            "Iteration 47/100, SAM Loss: 0.24541647732257843\n",
            "Iteration 48/100, SAM Loss: 0.3870249390602112\n",
            "Iteration 49/100, SAM Loss: 0.5664736032485962\n",
            "Iteration 50/100, SAM Loss: 0.2771695852279663\n",
            "Iteration 51/100, SAM Loss: 0.4162723422050476\n",
            "Iteration 52/100, SAM Loss: 0.5538631677627563\n",
            "Iteration 53/100, SAM Loss: 0.3530474901199341\n",
            "Iteration 54/100, SAM Loss: 0.321624755859375\n",
            "Iteration 55/100, SAM Loss: 0.2875598073005676\n",
            "Iteration 56/100, SAM Loss: 0.4385901689529419\n",
            "Iteration 57/100, SAM Loss: 0.3407655954360962\n",
            "Iteration 58/100, SAM Loss: 0.40364283323287964\n",
            "Iteration 59/100, SAM Loss: 0.214090958237648\n",
            "Iteration 60/100, SAM Loss: 0.31608790159225464\n",
            "Iteration 61/100, SAM Loss: 0.28866517543792725\n",
            "Iteration 62/100, SAM Loss: 0.6384094953536987\n",
            "Iteration 63/100, SAM Loss: 0.4419856667518616\n",
            "Iteration 64/100, SAM Loss: 0.26181888580322266\n",
            "Iteration 65/100, SAM Loss: 0.4813675880432129\n",
            "Iteration 66/100, SAM Loss: 0.24956972897052765\n",
            "Iteration 67/100, SAM Loss: 0.3021933436393738\n",
            "Iteration 68/100, SAM Loss: 0.4233914017677307\n",
            "Iteration 69/100, SAM Loss: 0.47525423765182495\n",
            "Iteration 70/100, SAM Loss: 0.3970821499824524\n",
            "Iteration 71/100, SAM Loss: 0.14615072309970856\n",
            "Iteration 72/100, SAM Loss: 0.6457681655883789\n",
            "Iteration 73/100, SAM Loss: 0.31912702322006226\n",
            "Iteration 74/100, SAM Loss: 0.2718658447265625\n",
            "Iteration 75/100, SAM Loss: 0.8534344434738159\n",
            "Iteration 76/100, SAM Loss: 0.285683810710907\n",
            "Iteration 77/100, SAM Loss: 0.4086562991142273\n",
            "Iteration 78/100, SAM Loss: 0.4610852003097534\n",
            "Iteration 79/100, SAM Loss: 0.22846479713916779\n",
            "Iteration 80/100, SAM Loss: 0.18093879520893097\n",
            "Iteration 81/100, SAM Loss: 0.20897509157657623\n",
            "Iteration 82/100, SAM Loss: 0.2181577831506729\n",
            "Iteration 83/100, SAM Loss: 0.619348406791687\n",
            "Iteration 84/100, SAM Loss: 0.33979785442352295\n",
            "Iteration 85/100, SAM Loss: 0.3302231431007385\n",
            "Iteration 86/100, SAM Loss: 0.1712232381105423\n",
            "Iteration 87/100, SAM Loss: 0.24738843739032745\n",
            "Iteration 88/100, SAM Loss: 0.2677760124206543\n",
            "Iteration 89/100, SAM Loss: 0.19652719795703888\n",
            "Iteration 90/100, SAM Loss: 0.26968973875045776\n",
            "Iteration 91/100, SAM Loss: 0.6346652507781982\n",
            "Iteration 92/100, SAM Loss: 0.26566189527511597\n",
            "Iteration 93/100, SAM Loss: 0.42121225595474243\n",
            "Iteration 94/100, SAM Loss: 0.4140808582305908\n",
            "Iteration 95/100, SAM Loss: 0.4801595211029053\n",
            "Iteration 96/100, SAM Loss: 0.2334715873003006\n",
            "Iteration 97/100, SAM Loss: 0.400063693523407\n",
            "Iteration 98/100, SAM Loss: 0.3304874300956726\n",
            "Iteration 99/100, SAM Loss: 0.5473588705062866\n",
            "Iteration 100/100, SAM Loss: 0.4209577441215515\n"
          ]
        }
      ],
      "source": [
        "# Task 1 - Question 2 - Part b\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "dataset_name = 'MNIST'\n",
        "data_path = './data'\n",
        "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, test_loader = get_dataset(dataset_name, data_path)\n",
        "\n",
        "batch_size = 256\n",
        "real_data_loader = DataLoader(dst_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "synthetic_data = torch.randn(num_classes, channel, im_size[0], im_size[1], requires_grad=True, device=device)\n",
        "\n",
        "model_name = 'ConvNetD3'\n",
        "model = get_network(model_name, channel, num_classes, im_size).to(device)\n",
        "\n",
        "K = 100\n",
        "T = 10\n",
        "eta_S = 0.1\n",
        "lambda_param = 0.01\n",
        "\n",
        "optimizer_syn = optim.SGD([synthetic_data], lr=eta_S)\n",
        "\n",
        "for k in range(K):\n",
        "    model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
        "    optimizer_model = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    for t in range(T):\n",
        "        optimizer_syn.zero_grad()\n",
        "        optimizer_model.zero_grad()\n",
        "\n",
        "        real_images, real_labels = next(iter(real_data_loader))\n",
        "        real_images, real_labels = real_images.to(device), real_labels.to(device)\n",
        "\n",
        "        indices = torch.randperm(real_images.size(0))[:10]\n",
        "        real_images_subset = real_images[indices]\n",
        "        real_labels_subset = real_labels[indices]\n",
        "\n",
        "        outputs_real = model(real_images_subset)\n",
        "        outputs_syn = model(synthetic_data)\n",
        "\n",
        "        loss = match_loss(outputs_syn, outputs_real, args) + lambda_param\n",
        "        loss.backward()\n",
        "        optimizer_syn.step()\n",
        "\n",
        "    print(f\"Iteration {k + 1}/{K}, SAM Loss: {loss.item()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BjZ40ls1DZEe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "3a2af69d-01b8-419e-ca6d-a3e8fdac6d71"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Task 1 - Question 2 - Part c\n",
        "\n",
        "synthetic_data = synthetic_data.detach().cpu()\n",
        "\n",
        "num_classes = synthetic_data.size(0)\n",
        "\n",
        "fig, axes = plt.subplots(1, num_classes, figsize=(15, 2))\n",
        "for i in range(num_classes):\n",
        "    ax = axes[i]\n",
        "    ax.imshow(synthetic_data[i].squeeze().numpy(), cmap='gray')\n",
        "    ax.axis('off')\n",
        "    ax.set_title(f\"Class {i}\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1 - Question 2 - Part d\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "dataset_name = 'MNIST'\n",
        "data_path = './data'\n",
        "channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, test_loader = get_dataset(dataset_name, data_path)\n",
        "\n",
        "batch_size = 256\n",
        "real_data_loader = DataLoader(dst_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "mean = 0.0\n",
        "std = 1.0\n",
        "\n",
        "synthetic_data = torch.normal(mean=mean, std=std, size=(num_classes, channel, im_size[0], im_size[1]), requires_grad=True, device=device)\n",
        "\n",
        "\n",
        "model_name = 'ConvNetD3'\n",
        "model = get_network(model_name, channel, num_classes, im_size).to(device)\n",
        "\n",
        "K = 100\n",
        "T = 10\n",
        "eta_S = 0.1\n",
        "lambda_param = 0.01\n",
        "\n",
        "optimizer_syn = optim.SGD([synthetic_data], lr=eta_S)\n",
        "\n",
        "for k in range(K):\n",
        "    model.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
        "    optimizer_model = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    for t in range(T):\n",
        "        optimizer_syn.zero_grad()\n",
        "        optimizer_model.zero_grad()\n",
        "\n",
        "        real_images, real_labels = next(iter(real_data_loader))\n",
        "        real_images, real_labels = real_images.to(device), real_labels.to(device)\n",
        "\n",
        "        indices = torch.randperm(real_images.size(0))[:10]\n",
        "        real_images_subset = real_images[indices]\n",
        "        real_labels_subset = real_labels[indices]\n",
        "\n",
        "        outputs_real = model(real_images_subset)\n",
        "        outputs_syn = model(synthetic_data)\n",
        "\n",
        "        loss = match_loss(outputs_syn, outputs_real, args) + lambda_param\n",
        "        loss.backward()\n",
        "        optimizer_syn.step()\n",
        "\n",
        "    print(f\"Iteration {k + 1}/{K}, SAM Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOE5_k5RF-KD",
        "outputId": "c13f5340-c15c-4139-ac8b-e926d4230120"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Iteration 1/100, SAM Loss: 0.17208893597126007\n",
            "Iteration 2/100, SAM Loss: 0.5529948472976685\n",
            "Iteration 3/100, SAM Loss: 0.3486648201942444\n",
            "Iteration 4/100, SAM Loss: 0.36256349086761475\n",
            "Iteration 5/100, SAM Loss: 0.2844945192337036\n",
            "Iteration 6/100, SAM Loss: 0.5611536502838135\n",
            "Iteration 7/100, SAM Loss: 0.21046508848667145\n",
            "Iteration 8/100, SAM Loss: 0.3599570393562317\n",
            "Iteration 9/100, SAM Loss: 0.37686455249786377\n",
            "Iteration 10/100, SAM Loss: 0.21103163063526154\n",
            "Iteration 11/100, SAM Loss: 0.5469302535057068\n",
            "Iteration 12/100, SAM Loss: 0.39416569471359253\n",
            "Iteration 13/100, SAM Loss: 0.22358949482440948\n",
            "Iteration 14/100, SAM Loss: 0.42416101694107056\n",
            "Iteration 15/100, SAM Loss: 0.4253951907157898\n",
            "Iteration 16/100, SAM Loss: 0.19082404673099518\n",
            "Iteration 17/100, SAM Loss: 0.34168940782546997\n",
            "Iteration 18/100, SAM Loss: 0.11208934336900711\n",
            "Iteration 19/100, SAM Loss: 0.21625222265720367\n",
            "Iteration 20/100, SAM Loss: 0.18257315456867218\n",
            "Iteration 21/100, SAM Loss: 0.4579952359199524\n",
            "Iteration 22/100, SAM Loss: 0.29911667108535767\n",
            "Iteration 23/100, SAM Loss: 0.43610090017318726\n",
            "Iteration 24/100, SAM Loss: 0.4057583808898926\n",
            "Iteration 25/100, SAM Loss: 0.34951072931289673\n",
            "Iteration 26/100, SAM Loss: 0.3394973874092102\n",
            "Iteration 27/100, SAM Loss: 0.19402261078357697\n",
            "Iteration 28/100, SAM Loss: 0.24549855291843414\n",
            "Iteration 29/100, SAM Loss: 0.6173340082168579\n",
            "Iteration 30/100, SAM Loss: 0.42571157217025757\n",
            "Iteration 31/100, SAM Loss: 0.3711872100830078\n",
            "Iteration 32/100, SAM Loss: 0.30868130922317505\n",
            "Iteration 33/100, SAM Loss: 0.3016588091850281\n",
            "Iteration 34/100, SAM Loss: 0.4673686623573303\n",
            "Iteration 35/100, SAM Loss: 0.1446036845445633\n",
            "Iteration 36/100, SAM Loss: 0.48025190830230713\n",
            "Iteration 37/100, SAM Loss: 0.20160438120365143\n",
            "Iteration 38/100, SAM Loss: 0.4312594532966614\n",
            "Iteration 39/100, SAM Loss: 0.4348612427711487\n",
            "Iteration 40/100, SAM Loss: 0.24549300968647003\n",
            "Iteration 41/100, SAM Loss: 0.7557035684585571\n",
            "Iteration 42/100, SAM Loss: 0.3334808349609375\n",
            "Iteration 43/100, SAM Loss: 0.28917479515075684\n",
            "Iteration 44/100, SAM Loss: 0.33663350343704224\n",
            "Iteration 45/100, SAM Loss: 0.42003577947616577\n",
            "Iteration 46/100, SAM Loss: 0.29062288999557495\n",
            "Iteration 47/100, SAM Loss: 0.2378469854593277\n",
            "Iteration 48/100, SAM Loss: 0.3165261745452881\n",
            "Iteration 49/100, SAM Loss: 0.27829301357269287\n",
            "Iteration 50/100, SAM Loss: 0.8452643156051636\n",
            "Iteration 51/100, SAM Loss: 0.4015212059020996\n",
            "Iteration 52/100, SAM Loss: 0.2893306612968445\n",
            "Iteration 53/100, SAM Loss: 0.23248697817325592\n",
            "Iteration 54/100, SAM Loss: 0.30041635036468506\n",
            "Iteration 55/100, SAM Loss: 0.5387978553771973\n",
            "Iteration 56/100, SAM Loss: 0.17420734465122223\n",
            "Iteration 57/100, SAM Loss: 0.39712655544281006\n",
            "Iteration 58/100, SAM Loss: 0.17649246752262115\n",
            "Iteration 59/100, SAM Loss: 0.3788105845451355\n",
            "Iteration 60/100, SAM Loss: 0.258747935295105\n",
            "Iteration 61/100, SAM Loss: 0.33996278047561646\n",
            "Iteration 62/100, SAM Loss: 0.9556266069412231\n",
            "Iteration 63/100, SAM Loss: 0.4480028748512268\n",
            "Iteration 64/100, SAM Loss: 0.20549626648426056\n",
            "Iteration 65/100, SAM Loss: 0.46076011657714844\n",
            "Iteration 66/100, SAM Loss: 0.27163928747177124\n",
            "Iteration 67/100, SAM Loss: 0.48525500297546387\n",
            "Iteration 68/100, SAM Loss: 0.21906591951847076\n",
            "Iteration 69/100, SAM Loss: 0.3015202283859253\n",
            "Iteration 70/100, SAM Loss: 0.1709468513727188\n",
            "Iteration 71/100, SAM Loss: 0.3617801070213318\n",
            "Iteration 72/100, SAM Loss: 0.5524179935455322\n",
            "Iteration 73/100, SAM Loss: 0.6234087944030762\n",
            "Iteration 74/100, SAM Loss: 0.33454829454421997\n",
            "Iteration 75/100, SAM Loss: 0.3208925127983093\n",
            "Iteration 76/100, SAM Loss: 0.3559951186180115\n",
            "Iteration 77/100, SAM Loss: 0.25218772888183594\n",
            "Iteration 78/100, SAM Loss: 0.34314602613449097\n",
            "Iteration 79/100, SAM Loss: 0.3243417739868164\n",
            "Iteration 80/100, SAM Loss: 0.5457608699798584\n",
            "Iteration 81/100, SAM Loss: 0.3992087244987488\n",
            "Iteration 82/100, SAM Loss: 0.37620729207992554\n",
            "Iteration 83/100, SAM Loss: 0.7056666612625122\n",
            "Iteration 84/100, SAM Loss: 0.18620409071445465\n",
            "Iteration 85/100, SAM Loss: 0.8247392177581787\n",
            "Iteration 86/100, SAM Loss: 0.381117582321167\n",
            "Iteration 87/100, SAM Loss: 0.2968377470970154\n",
            "Iteration 88/100, SAM Loss: 0.5483874082565308\n",
            "Iteration 89/100, SAM Loss: 0.30190569162368774\n",
            "Iteration 90/100, SAM Loss: 0.4205167889595032\n",
            "Iteration 91/100, SAM Loss: 0.30531078577041626\n",
            "Iteration 92/100, SAM Loss: 0.47588807344436646\n",
            "Iteration 93/100, SAM Loss: 0.16328872740268707\n",
            "Iteration 94/100, SAM Loss: 0.35386747121810913\n",
            "Iteration 95/100, SAM Loss: 0.32119423151016235\n",
            "Iteration 96/100, SAM Loss: 0.45170801877975464\n",
            "Iteration 97/100, SAM Loss: 0.45963168144226074\n",
            "Iteration 98/100, SAM Loss: 0.333162784576416\n",
            "Iteration 99/100, SAM Loss: 0.4637511372566223\n",
            "Iteration 100/100, SAM Loss: 0.1858154684305191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uPs-Na4GGK9K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}